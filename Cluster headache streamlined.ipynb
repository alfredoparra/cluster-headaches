{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf3951f3-797a-4503-88a2-f161aa79744e",
   "metadata": {},
   "source": [
    "# Cluster headache simulations: Streamlined full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "556a9ef9-dc4a-4e08-9640-d37ba58117f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import lognorm, gmean, rv_discrete, beta, truncnorm, expon\n",
    "from scipy.optimize import minimize, curve_fit\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b181ac74-01a0-4029-a7c3-cc6a5d966344",
   "metadata": {},
   "source": [
    "## Global statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "892c53b8-6c42-4d57-b168-dda0a3993948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the overall population\n",
    "annual_prevalence = 53/100000 # 53 per 100,000 (95% CI: 26, 95) of adults\n",
    "world_population = 8_200_000_000\n",
    "adult_fraction = 0.72\n",
    "total_ch_sufferers = world_population * adult_fraction * annual_prevalence # Estimated global CH sufferers\n",
    "\n",
    "# Define the proportions for each group\n",
    "prop_episodic = 0.80\n",
    "prop_chronic = 1 - prop_episodic\n",
    "prop_treated = 0.48\n",
    "prop_untreated = 1 - prop_treated\n",
    "\n",
    "# Define the groups\n",
    "ch_groups = {\n",
    "    'Episodic Treated': int(total_ch_sufferers * prop_episodic * prop_treated),\n",
    "    'Episodic Untreated': int(total_ch_sufferers * prop_episodic * prop_untreated),\n",
    "    'Chronic Treated': int(total_ch_sufferers * prop_chronic * prop_treated),\n",
    "    'Chronic Untreated': int(total_ch_sufferers * prop_chronic * prop_untreated)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098d03b0-b268-43da-accf-3daef6965063",
   "metadata": {},
   "source": [
    "## Annual bout frequency for episodic patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8d8cbfa-e84a-41b9-a8cc-df1fbcdbf8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    # Discretized approximation for a distribution with mean 1.2, SD 1.1\n",
    "    'Gaul': {'n': 209, 'dist': {1: 0.6, 2: 0.3, 3: 0.1}},  \n",
    "    \n",
    "    # Split \"<1/year\" between 0 and 1, \">1/year\" between 2 and 3\n",
    "    'Li': {'n': 327, 'dist': {0.5: 0.416, 1: 0.370, 2.5: 0.214}},\n",
    "    \n",
    "    # Split \"1/1.5-2 years\" between 0 and 1\n",
    "    'Friedman': {'n': 50, 'dist': {0.5: 0.46, 1: 0.54}},\n",
    "    \n",
    "    # Split \"<1/year\" between 0 and 1\n",
    "    'Ekbom': {'n': 105, 'dist': {0.5: 0.14, 1: 0.40, 2: 0.31, 3: 0.15}},\n",
    "    \n",
    "    # Split \"1-2/year\" evenly between 1 and 2\n",
    "    'Manzoni': {'n': 161, 'dist': {1: 0.27, 1.5: 0.73}},\n",
    "    \n",
    "    # Converted from remission periods to bouts/year, chronic cases removed\n",
    "    'Sutherland': {'n': 49, 'dist': {\n",
    "        0.5: 0.512+0.174,  # 1-5 years, adding >5 years for simplicity\n",
    "        1: 0.140,    # 6-12 months\n",
    "        2: 0.174     # 3-6 months\n",
    "    }},\n",
    "    \n",
    "    # Estimated from remission periods, splitting some categories\n",
    "    'Kudrow': {'n': 428, 'dist': {0.5: 0.19, 1: 0.67, 2.5: 0.14}}\n",
    "}\n",
    "\n",
    "# Combine distributions\n",
    "combined_dist = {}\n",
    "total_n = sum(study['n'] for study in data.values())\n",
    "\n",
    "for study in data.values():\n",
    "    weight = study['n'] / total_n\n",
    "    for bouts, prob in study['dist'].items():\n",
    "        combined_dist[bouts] = combined_dist.get(bouts, 0) + prob * weight\n",
    "\n",
    "# Normalize the combined distribution\n",
    "total_prob = sum(combined_dist.values())\n",
    "combined_dist = {k: v/total_prob for k, v in combined_dist.items()}\n",
    "\n",
    "# Create custom discrete distribution\n",
    "bouts_per_year = rv_discrete(values=(list(combined_dist.keys()), list(combined_dist.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d4b35d-7e8a-4631-860b-ddd1ce2bcfea",
   "metadata": {},
   "source": [
    "## Bout duration for episodic patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3ae9946-c808-4148-b757-2285947d603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "sample_sizes = []\n",
    "\n",
    "# Gaul et al. (2012)\n",
    "data.append(8.5)\n",
    "sample_sizes.append(209)\n",
    "\n",
    "# Li et al. (2022)\n",
    "total_li = 327\n",
    "original_proportions = np.array([0.104, 0.235, 0.502, 0.131])\n",
    "sum_proportions = np.sum(original_proportions)\n",
    "new_proportions = original_proportions / sum_proportions\n",
    "data.extend([1, gmean([2, 4]), gmean([4, 8]), 8])\n",
    "sample_sizes.extend([int(prop * total_li) for prop in new_proportions])\n",
    "\n",
    "# Friedman & Mikropoulos (1958)\n",
    "data.append(gmean([6, 8]))\n",
    "sample_sizes.append(50)\n",
    "\n",
    "# Ekbom (1970)\n",
    "data.append(gmean([4, 12]))\n",
    "sample_sizes.append(105)\n",
    "\n",
    "# Lance & Anthony (1971)\n",
    "data.append(gmean([2, 12]))\n",
    "sample_sizes.append(60)\n",
    "\n",
    "# Sutherland & Eadie (1972)\n",
    "total_sutherland = 58\n",
    "data.extend([np.mean([0, 4]), gmean([5, 13]), gmean([14, 26]), gmean([27, 52])])\n",
    "sample_sizes.extend([int(0.23 * total_sutherland), int(0.45 * total_sutherland), \n",
    "                     int(0.19 * total_sutherland), int(0.14 * total_sutherland)])\n",
    "\n",
    "# Rozen & Fishman (2012)\n",
    "data.append(10.3)\n",
    "sample_sizes.append(101)\n",
    "\n",
    "# Manzoni et al. (1983)\n",
    "data.append(gmean([4, 8]))\n",
    "sample_sizes.append(161)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "data = np.array(data)\n",
    "sample_sizes = np.array(sample_sizes)\n",
    "\n",
    "# Use sample sizes as weights\n",
    "weights = sample_sizes / np.sum(sample_sizes)\n",
    "\n",
    "# Fitting the lognormal distribution\n",
    "def neg_log_likelihood(params):\n",
    "    mu, sigma = params\n",
    "    return -np.sum(weights * lognorm.logpdf(data, s=sigma, scale=np.exp(mu)))\n",
    "\n",
    "initial_params = [np.log(np.average(data, weights=weights)), 0.5]\n",
    "result = minimize(neg_log_likelihood, initial_params, method='Nelder-Mead')\n",
    "optimal_mu, optimal_sigma = result.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe9a91f-6d8f-465b-8111-bd5b266409ff",
   "metadata": {},
   "source": [
    "## Modeling attacks per day for both episodic and chronic CH sufferers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7d96471-3973-42f1-b2f5-d141ca6b2da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lognormal(mean, std):\n",
    "    \"\"\"\n",
    "    Fit a lognormal distribution given mean and standard deviation.\n",
    "    Returns the mu and sigma parameters of the lognormal distribution.\n",
    "    \"\"\"\n",
    "    variance = std**2\n",
    "    mu = np.log(mean**2 / np.sqrt(variance + mean**2))\n",
    "    sigma = np.sqrt(np.log(1 + variance / mean**2))\n",
    "    return mu, sigma\n",
    "\n",
    "def truncated_lognorm_pdf(x, mu, sigma, upper_bound=np.inf):\n",
    "    \"\"\"\n",
    "    Calculate the PDF of a truncated lognormal distribution.\n",
    "    \"\"\"\n",
    "    pdf = lognorm.pdf(x, s=sigma, scale=np.exp(mu))\n",
    "    cdf_upper = lognorm.cdf(upper_bound, s=sigma, scale=np.exp(mu))\n",
    "    return np.where(x <= upper_bound, pdf / cdf_upper, 0)\n",
    "\n",
    "def estimate_untreated(treated_mean, treated_std, treatment_effect=1.05):\n",
    "    \"\"\"\n",
    "    Function to estimate untreated values\n",
    "    \"\"\"\n",
    "    cv = treated_std / treated_mean  # Coefficient of variation\n",
    "    untreated_mean = treated_mean * treatment_effect\n",
    "    untreated_std = untreated_mean * cv\n",
    "    return untreated_mean, untreated_std\n",
    "\n",
    "def generate_attacks_per_day(is_chronic, is_treated, max_daily_ch=np.inf):\n",
    "    if is_chronic:\n",
    "        if is_treated:\n",
    "            mu, sigma = chronic_treated_mu, chronic_treated_sigma\n",
    "        else:\n",
    "            mu, sigma = chronic_untreated_mu, chronic_untreated_sigma\n",
    "    else:\n",
    "        if is_treated:\n",
    "            mu, sigma = episodic_treated_mu, episodic_treated_sigma\n",
    "        else:\n",
    "            mu, sigma = episodic_untreated_mu, episodic_untreated_sigma\n",
    "    \n",
    "    while True:\n",
    "        attacks = lognorm.rvs(s=sigma, scale=np.exp(mu))\n",
    "        if attacks <= max_daily_ch:\n",
    "            break\n",
    "    \n",
    "    return max(1, round(attacks))\n",
    "\n",
    "# Gaul et al. (2012) data for treated patients (not explicitly stated in the paper,\n",
    "# but highly likely given that they were German patients from a hospital)\n",
    "episodic_treated_mean, episodic_treated_std = 3.1, 2.1\n",
    "chronic_treated_mean, chronic_treated_std = 3.3, 3.0\n",
    "\n",
    "# Estimating untreated values\n",
    "episodic_untreated_mean, episodic_untreated_std = estimate_untreated(episodic_treated_mean, episodic_treated_std)\n",
    "chronic_untreated_mean, chronic_untreated_std = estimate_untreated(chronic_treated_mean, chronic_treated_std)\n",
    "\n",
    "# Fit lognormal distributions\n",
    "episodic_treated_mu, episodic_treated_sigma = fit_lognormal(episodic_treated_mean, episodic_treated_std)\n",
    "chronic_treated_mu, chronic_treated_sigma = fit_lognormal(chronic_treated_mean, chronic_treated_std)\n",
    "episodic_untreated_mu, episodic_untreated_sigma = fit_lognormal(episodic_untreated_mean, episodic_untreated_std)\n",
    "chronic_untreated_mu, chronic_untreated_sigma = fit_lognormal(chronic_untreated_mean, chronic_untreated_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6552dd-33f5-4261-b918-7f325ad291e3",
   "metadata": {},
   "source": [
    "## Simulating active days for chronic patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a0027d8-7530-4397-97cb-3a3d2b319e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chronic_active_days():\n",
    "    while True:\n",
    "        # Generate total attack days in a year\n",
    "        active_days = int(lognorm.rvs(s=.5, scale=np.exp(np.log(200))))\n",
    "        \n",
    "        # Ensure active_days is never over 365\n",
    "        active_days = min(active_days, 365)\n",
    "        \n",
    "        return active_days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeded4a2-1b05-4b02-b45b-8708c5e7ef45",
   "metadata": {},
   "source": [
    "## Simulating attack durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3726dad-787b-45cb-94fb-09b78dcbc44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_attack_duration(is_chronic, is_treated, max_intensities, size):\n",
    "    # Base parameters for lognormal distribution\n",
    "    mu = 4.0\n",
    "    sigma = 0.4\n",
    "    \n",
    "    if is_chronic:\n",
    "        mu += 0.3  # Slightly longer attacks for chronic sufferers\n",
    "    \n",
    "    # Generate base durations\n",
    "    base_durations = lognorm.rvs(s=sigma, scale=np.exp(mu), size=size)\n",
    "    \n",
    "    # Adjust durations based on max intensities\n",
    "    # This creates a positive correlation between intensity and duration\n",
    "    intensity_factor = 0.1064 * max_intensities + 0.5797 # Scale factor based on intensity\n",
    "    adjusted_durations = base_durations * intensity_factor\n",
    "\n",
    "    if is_treated:\n",
    "        # Reasoning: Patients with access to treatment will, in some cases, manage to reduce\n",
    "        # the duration of the attack. However, according to Snoer et al., mild attacks are often\n",
    "        # not treated despite having access to treatment, and those are typically shorter, which explains\n",
    "        # the seemingly contradictory statistic about untreated attacks being shorter.\n",
    "        \n",
    "        max_effect = 0.3  # Up to 30% duration reduction for highest intensity\n",
    "        \n",
    "        intensity_normalized = (max_intensities - 1) / 9\n",
    "        \n",
    "        # The more intense the attack, the more a patient will use treatment to abort the attack (shorter duration)\n",
    "        mean_effect = 1 - (max_effect * intensity_normalized)\n",
    "        \n",
    "        # However, treatment might or might not be effective, so model this using a beta distribution.\n",
    "        a, b = 5, 2\n",
    "        treatment_effect = beta.rvs(a, b, size=size) * mean_effect\n",
    "        \n",
    "        # Apply treatment effect\n",
    "        adjusted_durations *= treatment_effect\n",
    "    \n",
    "    return np.clip(np.round(adjusted_durations).astype(int), 15, 360)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8092fdf8-4a7f-4837-ba04-8d2d3393ce60",
   "metadata": {},
   "source": [
    "## Simulating max pain intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a13c022-6bc6-42b7-bb11-0e8c0849af3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_max_pain_intensity(is_treated, size):\n",
    "    \n",
    "    mean_mild_moderate = 4.0\n",
    "    sd_mild_moderate = 2.0\n",
    "    mean_moderate_severe = 7.5\n",
    "    sd_moderate_severe = 2.0\n",
    "    scale_very_severe = .7 if is_treated else 0.5\n",
    "    \n",
    "    mild_to_moderate = truncnorm.rvs((1-mean_mild_moderate)/sd_mild_moderate, np.inf, loc=mean_mild_moderate, scale=sd_mild_moderate, size=size)\n",
    "    moderate_to_severe = truncnorm.rvs((1-mean_moderate_severe)/sd_moderate_severe, np.inf, loc=mean_moderate_severe, scale=sd_moderate_severe, size=size)\n",
    "    very_severe = 10 - expon.rvs(scale=scale_very_severe, size=size)\n",
    "    \n",
    "    if is_treated:\n",
    "        # For treated patients:\n",
    "        choices = np.random.choice(3, size=size, p=[0.40, 0.35, 0.25])\n",
    "    else:\n",
    "        # For untreated patients:\n",
    "        choices = np.random.choice(3, size=size, p=[0.20, 0.50, 0.30])\n",
    "\n",
    "    intensities = np.where(choices == 0, mild_to_moderate,\n",
    "                  np.where(choices == 1, moderate_to_severe, very_severe))\n",
    "    \n",
    "    return np.round(np.clip(intensities, 1, 10), decimals=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3b7a3a-69d4-4fea-9af9-e55877ef5822",
   "metadata": {},
   "source": [
    "## Defining classes for attacks and patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2daa44c-99bd-4c16-b960-235d4d4387ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Attack:\n",
    "    total_duration: int\n",
    "    max_intensity: float\n",
    "    max_intensity_duration: int\n",
    "\n",
    "class Patient:\n",
    "    def __init__(self, is_chronic, is_treated):\n",
    "        self.is_chronic = is_chronic\n",
    "        self.is_treated = is_treated\n",
    "        self.attacks = []\n",
    "        self.generate_profile()\n",
    "        self.pre_generate_attack_pool()\n",
    "\n",
    "    def generate_profile(self):\n",
    "        if self.is_chronic:\n",
    "            self.active_days = generate_chronic_active_days()\n",
    "        else:\n",
    "            self.annual_bouts = bouts_per_year.rvs()\n",
    "            self.bout_durations = self.generate_bout_durations()\n",
    "\n",
    "    def pre_generate_attack_pool(self):\n",
    "        # Estimate the maximum number of attacks in a year\n",
    "        if self.is_chronic:\n",
    "            max_attacks = self.active_days * 8  # Assuming max 8 attacks per day\n",
    "        else:\n",
    "            max_attacks = sum(self.bout_durations) * 8\n",
    "\n",
    "        # Generate a pool of attacks\n",
    "        max_intensities = generate_max_pain_intensity(is_treated=self.is_treated, size=max_attacks)\n",
    "        total_durations = generate_attack_duration(self.is_chronic, self.is_treated, max_intensities, size=max_attacks)\n",
    "        # Assuming onset and offset phases take up 15% of the total attack duration each\n",
    "        max_intensity_durations = np.round(0.7 * total_durations).astype(int)\n",
    "\n",
    "        self.attack_pool = [Attack(total_durations[i], max_intensities[i], max_intensity_durations[i])\n",
    "                            for i in range(max_attacks)]\n",
    "        self.pool_index = 0\n",
    "        \n",
    "    def generate_bout_durations(self):\n",
    "        # Use the lognormal distribution for bout durations\n",
    "        n_bouts = np.ceil(self.annual_bouts)\n",
    "        durations = lognorm.rvs(s=optimal_sigma, scale=np.exp(optimal_mu), size=int(n_bouts))\n",
    "        \n",
    "        # Adjust the last bout duration if annual_bouts is not an integer\n",
    "        if self.annual_bouts != int(self.annual_bouts):\n",
    "            durations[-1] *= (self.annual_bouts - int(self.annual_bouts))\n",
    "        \n",
    "        return [max(1, int(duration * 7)) for duration in durations]  # Convert weeks to days, ensure at least 1 day\n",
    "\n",
    "    def generate_year_of_attacks(self):\n",
    "        self.attacks = []\n",
    "        total_attacks = 0\n",
    "        if self.is_chronic:\n",
    "            for day in range(min(365, self.active_days)):\n",
    "                total_attacks += self.generate_day_attacks()\n",
    "        else:\n",
    "            for duration in self.bout_durations:\n",
    "                for day in range(duration):\n",
    "                    total_attacks += self.generate_day_attacks()\n",
    "        return total_attacks\n",
    "\n",
    "    def generate_day_attacks(self):\n",
    "        daily_attacks = 0\n",
    "        attacks_today = generate_attacks_per_day(self.is_chronic, self.is_treated)\n",
    "\n",
    "        for _ in range(attacks_today):\n",
    "            if self.pool_index >= len(self.attack_pool):\n",
    "                # If we've used all pre-generated attacks, generate more\n",
    "                self.pre_generate_attack_pool()\n",
    "            \n",
    "            self.attacks.append(self.attack_pool[self.pool_index])\n",
    "            self.pool_index += 1\n",
    "            daily_attacks += 1\n",
    "\n",
    "        return daily_attacks\n",
    "\n",
    "    def calculate_intensity_minutes(self):\n",
    "        intensity_minutes = {}\n",
    "        for attack in self.attacks:\n",
    "            intensity = round(attack.max_intensity, 1)  # Round to nearest 0.1\n",
    "            intensity_minutes[intensity] = intensity_minutes.get(intensity, 0) + attack.max_intensity_duration\n",
    "        return intensity_minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befadd6c-8886-46a4-87a0-6c0adb97ec92",
   "metadata": {},
   "source": [
    "## Running some simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb1ce84f-ce02-4b91-926b-adb49a04b846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_population(n_episodic_treated, n_episodic_untreated, n_chronic_treated, n_chronic_untreated):\n",
    "    population = []\n",
    "    for _ in range(n_episodic_treated):\n",
    "        population.append(Patient(is_chronic=False, is_treated=True))\n",
    "    for _ in range(n_episodic_untreated):\n",
    "        population.append(Patient(is_chronic=False, is_treated=False))\n",
    "    for _ in range(n_chronic_treated):\n",
    "        population.append(Patient(is_chronic=True, is_treated=True))\n",
    "    for _ in range(n_chronic_untreated):\n",
    "        population.append(Patient(is_chronic=True, is_treated=False))\n",
    "    return population\n",
    "\n",
    "def calculate_group_data(population, groups_simulated):\n",
    "    intensities = np.arange(0, 10.1, 0.1)\n",
    "    group_data = []\n",
    "    chronic_attacks = []\n",
    "    episodic_attacks = []\n",
    "    \n",
    "    all_treated_attacks = []\n",
    "    all_untreated_attacks = []\n",
    "    all_episodic_attacks = []\n",
    "    all_chronic_attacks = []\n",
    "    all_treated_intensities = []\n",
    "    all_untreated_intensities = []\n",
    "    all_episodic_intensities = []\n",
    "    all_chronic_intensities = []\n",
    "\n",
    "    for group_name, condition, n_patients in groups_simulated:\n",
    "        group_patients = [p for p in population if condition(p)]\n",
    "        total_intensity_minutes = {}\n",
    "        group_total_attacks = []\n",
    "        group_intensities = []\n",
    "        \n",
    "        for patient in group_patients:\n",
    "            total_attacks = patient.generate_year_of_attacks()\n",
    "            group_total_attacks.append(total_attacks)\n",
    "            \n",
    "            patient_intensity_minutes = patient.calculate_intensity_minutes()\n",
    "            for intensity, minutes in patient_intensity_minutes.items():\n",
    "                total_intensity_minutes[intensity] = total_intensity_minutes.get(intensity, 0) + minutes\n",
    "                group_intensities.extend([intensity] * int(minutes))\n",
    "        \n",
    "        intensity_minutes_average = [total_intensity_minutes.get(round(i, 1), 0) / n_patients for i in intensities]\n",
    "        intensity_minutes_total = [total_intensity_minutes.get(round(i, 1), 0) for i in intensities]\n",
    "        group_data.append((group_name, intensity_minutes_average, intensity_minutes_total, n_patients))\n",
    "        \n",
    "        # Calculate statistics\n",
    "        attack_stats = np.percentile(group_total_attacks, [25, 50, 75])\n",
    "        intensity_stats = np.percentile(group_intensities, [25, 50, 75])\n",
    "        \n",
    "        print(f\"{group_name}: N={n_patients}\")\n",
    "        print(f\"Attacks - Mean: {np.mean(group_total_attacks):.0f}, Median: {attack_stats[1]:.0f}, IQR: [{attack_stats[0]:.0f}, {attack_stats[2]:.0f}]\")\n",
    "        print(f\"Intensity - Mean: {np.mean(group_intensities):.1f}, Median: {intensity_stats[1]:.1f}, IQR: [{intensity_stats[0]:.1f}, {intensity_stats[2]:.1f}]\")\n",
    "        print()\n",
    "        \n",
    "        if 'Chronic' in group_name:\n",
    "            chronic_attacks.extend(group_total_attacks)\n",
    "            all_chronic_attacks.extend(group_total_attacks)\n",
    "            all_chronic_intensities.extend(group_intensities)\n",
    "        else:\n",
    "            episodic_attacks.extend(group_total_attacks)\n",
    "            all_episodic_attacks.extend(group_total_attacks)\n",
    "            all_episodic_intensities.extend(group_intensities)\n",
    "        \n",
    "        if 'Treated' in group_name:\n",
    "            all_treated_attacks.extend(group_total_attacks)\n",
    "            all_treated_intensities.extend(group_intensities)\n",
    "        else:\n",
    "            all_untreated_attacks.extend(group_total_attacks)\n",
    "            all_untreated_intensities.extend(group_intensities)\n",
    "    \n",
    "    # Print aggregate statistics\n",
    "    print(\"\\nAggregate Statistics:\")\n",
    "    print_aggregate_stats(\"All Treated\", all_treated_attacks, all_treated_intensities)\n",
    "    print_aggregate_stats(\"All Untreated\", all_untreated_attacks, all_untreated_intensities)\n",
    "    print_aggregate_stats(\"All Episodic\", all_episodic_attacks, all_episodic_intensities)\n",
    "    print_aggregate_stats(\"All Chronic\", all_chronic_attacks, all_chronic_intensities)\n",
    "    \n",
    "    return intensities, group_data\n",
    "\n",
    "def print_aggregate_stats(group_name, attacks, intensities):\n",
    "    attack_stats = np.percentile(attacks, [25, 50, 75])\n",
    "    intensity_stats = np.percentile(intensities, [25, 50, 75])\n",
    "    print(f\"{group_name}: N={len(attacks)}\")\n",
    "    print(f\"Attacks - Mean: {np.mean(attacks):.0f}, Median: {attack_stats[1]:.0f}, IQR: [{attack_stats[0]:.0f}, {attack_stats[2]:.0f}]\")\n",
    "    print(f\"Intensity - Mean: {np.mean(intensities):.1f}, Median: {intensity_stats[1]:.1f}, IQR: [{intensity_stats[0]:.1f}, {intensity_stats[2]:.1f}]\")\n",
    "    print()\n",
    "    \n",
    "def plot_data(intensities, group_data, y_label, title):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    for group_name, intensity_minutes, _, _ in group_data:\n",
    "        ax.plot(intensities, intensity_minutes, label=group_name, linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Max Pain Intensity')\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax.set_xlim(0, 10)\n",
    "    ax.set_ylim(bottom=0)\n",
    "    \n",
    "    ax.set_xticks(range(11))\n",
    "    \n",
    "    for i in range(1, 11):\n",
    "        ax.axvline(x=i, color='gray', linestyle=':', alpha=0.5)\n",
    "    \n",
    "    def format_with_commas(x, p):\n",
    "        return f\"{int(x):,}\"\n",
    "    \n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(format_with_commas))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25605fb5-9a5a-4520-9c75-b39d3d4cfb17",
   "metadata": {},
   "source": [
    "## Streamlit app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b325a07-f35a-46d0-a860-6bda5a6c6d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    st.title(\"Cluster Headache Simulation\")\n",
    "\n",
    "    # Sidebar for user inputs\n",
    "    st.sidebar.header(\"Parameters\")\n",
    "    \n",
    "    # Add sliders for key parameters\n",
    "    prop_chronic = st.sidebar.slider(\"Proportion of Chronic CH\", 0.0, 1.0, 0.2)\n",
    "    prop_treated = st.sidebar.slider(\"Proportion of Treated Patients\", 0.0, 1.0, 0.48)\n",
    "    n_patients = st.sidebar.slider(\"Number of Patients to Simulate\", 100, 10000, 1000)\n",
    "\n",
    "    # Calculate patient numbers\n",
    "    n_episodic_treated = int(n_patients * (1 - prop_chronic) * prop_treated)\n",
    "    n_episodic_untreated = int(n_patients * (1 - prop_chronic) * (1 - prop_treated))\n",
    "    n_chronic_treated = int(n_patients * prop_chronic * prop_treated)\n",
    "    n_chronic_untreated = int(n_patients * prop_chronic * (1 - prop_treated))\n",
    "\n",
    "    groups_simulated = [\n",
    "    (\"Episodic Treated\", lambda p: not p.is_chronic and p.is_treated, n_episodic_treated),\n",
    "    (\"Episodic Untreated\", lambda p: not p.is_chronic and not p.is_treated, n_episodic_untreated),\n",
    "    (\"Chronic Treated\", lambda p: p.is_chronic and p.is_treated, n_chronic_treated),\n",
    "    (\"Chronic Untreated\", lambda p: p.is_chronic and not p.is_treated, n_chronic_untreated)\n",
    "    ]\n",
    "\n",
    "    # Button to run simulation\n",
    "    if st.sidebar.button(\"Run Simulation\"):\n",
    "        # Run your simulation\n",
    "        population = generate_population(n_episodic_treated, n_episodic_untreated, n_chronic_treated, n_chronic_untreated)\n",
    "        intensities, group_data = calculate_group_data(population, groups_simulated)\n",
    "\n",
    "        # Display results\n",
    "        st.subheader(\"Simulation Results\")\n",
    "        \n",
    "        # Plot total minutes\n",
    "        fig1 = plot_data(intensities, [(name, total, _, _) for name, _, total, _ in group_data], \n",
    "                  'Total Minutes', 'Distribution of Time Spent at Different Max Pain Intensities')\n",
    "        st.pyplot(fig1)\n",
    "\n",
    "        # Plot average minutes\n",
    "        fig2 = plot_data(intensities, [(name, avg, _, _) for name, avg, _, _ in group_data], \n",
    "                  'Average Minutes', 'Distribution of Time Spent at Different Max Pain Intensities')\n",
    "        st.pyplot(fig2)\n",
    "\n",
    "        # Display some statistics\n",
    "        st.subheader(\"Statistics\")\n",
    "        for group_name, _, _, n_patients in group_data:\n",
    "            st.write(f\"{group_name}: {n_patients} patients\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9c6bff1-0fc7-47d3-8ec5-031511803366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Cluster headache streamlined.ipynb to script\n",
      "[NbConvertApp] Writing 20979 bytes to Cluster headache streamlined.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script Cluster\\ headache\\ streamlined.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
